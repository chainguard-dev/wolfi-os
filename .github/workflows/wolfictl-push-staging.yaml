name: Build Packages Staging using wolfictl

on:
  workflow_dispatch:
  push:
    branches:
      - main

env:
  PROJECT: staging-images-183e
  CLUSTER_NAME: tmp-cluster-staging-${{github.run_id}}
  CLUSTER_ZONE: us-central1-b
  SERVICE_ACCOUNT: staging-images-ci
  FQ_SERVICE_ACCOUNT: staging-images-ci@staging-images-183e.iam.gserviceaccount.com
  BUCKET: wolfi-registry-source/os/
  SRC_BUCKET: gs://wolfi-registry-destination/os/

jobs:
  setup-cluster:
    name: Setup build cluster
    runs-on: ubuntu-latest
    if: github.repository == 'wolfi-dev/os'

    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v3
        with:
          repository: wolfi-dev/wolfictl
          path: ${{github.workspace}}/wolfictl

      - uses: google-github-actions/auth@v0
        with:
          workload_identity_provider: "projects/567187841907/locations/global/workloadIdentityPools/staging-shared-9bd2/providers/staging-shared-gha"
          service_account: ${{env.FQ_SERVICE_ACCOUNT}}
      - uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{env.PROJECT}}
      - name: 'Use gcloud CLI'
        run: 'gcloud auth list --filter=status:ACTIVE --format="value(account)"'

      - name: Setup Build Cluster
        working-directory: ${{github.workspace}}/wolfictl
        run: |
          gcloud container clusters create "${CLUSTER_NAME}" \
            --enable-ip-alias \
            --network                       projects/staging-shared-7864/global/networks/staging-shared-a6474a3 \
            --subnetwork                    projects/staging-shared-7864/regions/us-central1/subnetworks/staging-shared-imgs-us-c1-209d340 \
            --cluster-secondary-range-name  gke-a-pods \
            --services-secondary-range-name gke-a-svcs \
            --tags                          "egress-inet" \
            --enable-dataplane-v2 \
            --enable-intra-node-visibility \
            --service-account "${FQ_SERVICE_ACCOUNT}" \
            --zone            "${CLUSTER_ZONE}" \
            --release-channel rapid \
            --workload-pool   "${PROJECT}.svc.id.goog" \
            --machine-type    e2-standard-32 \
            --num-nodes       1 \
            --spot  \
            --no-enable-autorepair

          gcloud container node-pools create arm-nodes \
            --cluster         "${CLUSTER_NAME}" \
            --zone            "${CLUSTER_ZONE}" \
            --tags            "egress-inet" \
            --service-account "${FQ_SERVICE_ACCOUNT}" \
            --machine-type    t2a-standard-32 \
            --num-nodes       1 \
            --spot  \
            --no-enable-autorepair

      - uses: imjasonh/gke-auth@v0.2.0
        with:
          project: "${PROJECT}"
          location: "${CLUSTER_ZONE}"
          cluster: "${CLUSTER_NAME}"

      - working-directory: ${{github.workspace}}/wolfictl
        run: ./scripts/setup-cluster.sh ${SERVICE_ACCOUNT}

  # TODO: Update source cache here, instead of in a separate workflow.
  #       This likely depends on making the source cache bucket configurable by
  #       wolfictl, or if we have staging builds reuse the prod source cache, then
  #       we only need to update it before prod builds.

  # TODO: Add build-amd64

  build-arm64:
    name: Build (arm64)
    runs-on: ubuntu-latest
    needs: setup-cluster

    permissions:
      id-token: write
      contents: read

    steps:
      - uses: google-github-actions/auth@v0
        with:
          workload_identity_provider: "projects/567187841907/locations/global/workloadIdentityPools/staging-shared-9bd2/providers/staging-shared-gha"
          service_account: ${{env.FQ_SERVICE_ACCOUNT}}
      - uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{env.PROJECT}}
      - uses: 'google-github-actions/get-gke-credentials@v0'
        with:
          cluster_name: ${{ env.CLUSTER_NAME }}
          location: ${{ env.CLUSTER_ZONE }}
      - run: gcloud auth configure-docker --quiet

      - uses: actions/checkout@v3
        with:
          repository: wolfi-dev/os
          path: ${{github.workspace}}/os

      - uses: docker://ghcr.io/wolfi-dev/wolfictl:latest@sha256:9b7fa38f57cec410c38936898f73cf81c408eac608cfa63d7acda2aca4d60e80
        with:
          entrypoint: wolfictl
          args: |
            pod \
            -d ${{github.workspace}}/os \
            --cpu=30 --ram=100Gi \
            --bucket=${{env.BUCKET}} \
            --src-bucket=${{env.SRC_BUCKET}} \
            --sdk-image ghcr.io/wolfi-dev/sdk:latest@sha256:8f48718d6a261b2c490a7e89e69f35afba4d1afb177baeaf7642f8e69fa4c63a \
            --pending-timeout=10m \
            --secret-key \
            --arch=arm64

  teardown-cluster:
    name: Teardown build cluster
    runs-on: ubuntu-latest
    needs: [build-arm64]
    if: always() && github.repository == 'wolfi-dev/os'

    permissions:
      id-token: write
      contents: read

    steps:
      - uses: google-github-actions/auth@v0
        with:
          workload_identity_provider: "projects/567187841907/locations/global/workloadIdentityPools/staging-shared-9bd2/providers/staging-shared-gha"
          service_account: ${{env.FQ_SERVICE_ACCOUNT}}
      - uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{env.PROJECT}}
      - uses: 'google-github-actions/get-gke-credentials@v0'
        with:
          cluster_name: ${{ env.CLUSTER_NAME }}
          location: ${{ env.CLUSTER_ZONE }}

      - name: Collect diagnostics
        if: always()
        run: |
          resources="pods daemonsets serviceaccounts namespaces"
          for ns in $(kubectl get ns -oname | cut -d'/' -f 2); do
            for resource in ${resources}; do
              echo --- $ns $resource ---
              kubectl get $resource -n${ns}
              for x in $(kubectl get $resource -n${ns} -oname || true); do
                echo "::group:: describe $resource $x"
                # Don't fail if the resource disappears midway.
                kubectl describe -n${ns} $x || true
                echo '::endgroup::'
              done
            done
          done

      - name: Teardown Build Cluster
        if: always()
        run: |
          gcloud container clusters delete "${CLUSTER_NAME}" \
            --zone "${CLUSTER_ZONE}" \
            --quiet
